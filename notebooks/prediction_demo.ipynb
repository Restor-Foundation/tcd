{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6a9406",
   "metadata": {},
   "source": [
    "This notebook shows a minimal example of loading a saved TCD model and running on a new image. All configuration details are stored in a YAML file and are handled by the model runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735cc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161eb2e",
   "metadata": {},
   "source": [
    "Let's load the model runner with the default config. This configuration file includes details for the model to be used, inference parameters (e.g. max number of instances), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3914c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = model.ModelRunner(\"default.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e555e03",
   "metadata": {},
   "source": [
    "And an image to test on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65bf71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/josh/.darwin/datasets/restor/stratified_test_data/images/5c15321f63d9810007f8b06f_10_00000.tif\"\n",
    "image = rasterio.open(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dcadd",
   "metadata": {},
   "source": [
    "Let's predict the results for this image. The first time this function is run, Torch will load the model so it'll take a bit of time. Repeat runs should be much faster. This model is run at native resolution (10 cm), but still does a good job at finding smaller trees in the image due to test-time augmentation.\n",
    "\n",
    "The results here are quite bad, because the image is reshaped to a maximum size of 1024 px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runner.predict_file(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b698210",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tree instances detected: {sum((results.pred_classes == 1) * (results.scores > 0.65))}\")\n",
    "print(f\"Canopy instances detected: {sum((results.pred_classes == 0) * (results.scores > 0.65))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130185fd",
   "metadata": {},
   "source": [
    "And visualise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.visualise(image.read().transpose(1,2,0), results, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa232a9",
   "metadata": {},
   "source": [
    "We can also try to detect instances in tiled mode, which works a lot better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runner.detect_tiled(image_path, tile_size=512, pad=100, skip_empty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13cb40",
   "metadata": {},
   "source": [
    "Let's plot the results - here as a simple mask by flattening the output instances into a single layer. This is much faster and more memory friendly than using Detectron's built-in visualiser. We'll also plot the tile boundaries as red boxes.\n",
    "\n",
    "Note we also use masked numpy arrays to display different segmentation layers to preserve transparency in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "extent=[image.bounds[0], image.bounds[2], image.bounds[1], image.bounds[3]]\n",
    "plt.imshow(image.read().transpose((1,2,0)), extent=extent)\n",
    "ax = plt.gca()\n",
    "\n",
    "threshold = 0.5\n",
    "image_mask = runner.merge_tiled_results(results, image, threshold)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    _, bbox = result\n",
    "    \n",
    "    rect = plt.Rectangle(xy=(bbox.minx, bbox.miny),\n",
    "                         width=bbox.maxx-bbox.minx,\n",
    "                         height=bbox.maxy-bbox.miny,\n",
    "                         alpha=0.25,\n",
    "                         linewidth=4,\n",
    "                         edgecolor='red',\n",
    "                         facecolor='none')\n",
    "    \n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "# Trees\n",
    "masked = np.ma.masked_where(image_mask[:,:,0] == 0, image_mask[:,:,0])\n",
    "plt.imshow(masked, alpha=0.8, extent=extent, cmap='Blues_r')\n",
    "\n",
    "# Trees\n",
    "masked = np.ma.masked_where(image_mask[:,:,1] == 0, image_mask[:,:,1])\n",
    "plt.imshow(masked, alpha=0.8, extent=extent, cmap='Reds_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42264650",
   "metadata": {},
   "source": [
    "Here's a more complex example where we have a large image that we want to resample and predict on. This could possibly be done natively using torchgeo too (TODO), but for now we can just resample the image at the appropriate resolution. This image is something like 20k x 20k pixels - far too large to process in one go. So we need to tile this time.\n",
    "\n",
    "The tile size here is relatively small, because there are some issues with memory consumption with larger images and large numbers of detected instances. The direct result of this is that it takes a long time. Unfortunately it's difficult to gracefully recover from OOM errors and this is something that we should think about working around, for example processing the image at the maximum tile size that will fit in memory, and progressively \"fix\" image regions that are too dense to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29004c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tile import Tiler, convert_to_projected\n",
    "#tiler = Tiler(\"./data\", \"./data\")\n",
    "#convert_to_projected(\"./data/5a04a02cbac48e5b1c01282b.tiff\", inplace=True)\n",
    "#tiler.resample(\"./data/5a04a02cbac48e5b1c01282b.tiff\", \"./data/5a04a02cbac48e5b1c01282b_10.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10448c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./data/5a04a02cbac48e5b1c01282b_10.tiff\"\n",
    "image = rasterio.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e358506",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runner.detect_tiled(image_path, tile_size=768, pad=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5524a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "extent=[image.bounds[0], image.bounds[2], image.bounds[1], image.bounds[3]]\n",
    "plt.imshow(image.read().transpose((1,2,0)), extent=extent)\n",
    "ax = plt.gca()\n",
    "\n",
    "threshold = 0.5\n",
    "image_mask = runner.merge_tiled_results(results, image, threshold)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    \n",
    "    _, bbox = result\n",
    "    \n",
    "    rect = plt.Rectangle(xy=(bbox.minx, bbox.miny),\n",
    "                         width=bbox.maxx-bbox.minx,\n",
    "                         height=bbox.maxy-bbox.miny,\n",
    "                         alpha=0.05,\n",
    "                         linewidth=4,\n",
    "                         edgecolor='red',\n",
    "                         facecolor='none')\n",
    "    \n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "# Trees\n",
    "masked = np.ma.masked_where(image_mask[:,:,0] == 0, image_mask[:,:,0])\n",
    "plt.imshow(masked, alpha=0.8, extent=extent, cmap='Blues_r')\n",
    "\n",
    "# Trees\n",
    "masked = np.ma.masked_where(image_mask[:,:,1] == 0, image_mask[:,:,1])\n",
    "plt.imshow(masked, alpha=0.8, extent=extent, cmap='Reds_r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
