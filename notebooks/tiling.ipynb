{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import rasterio\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71275bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcd_pipeline.data.dataset import SingleImageGeoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52144402",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = \"../data/5c15321f63d9810007f8b06f_10_00000.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa787748",
   "metadata": {},
   "source": [
    "Geospatial data can be extremely large while machine learning models are only able to predict small inputs due to memory constraints. Even using a high-end graphics card with > 32 GB of VRAM, predicting larger than 2048 x 2048 px tiles is difficult. As a result, predicting over tiles is the preferred way to process large images.\n",
    "\n",
    "We normally assume that CNNs are translation invariant. This means that a feature is fully visible, it should be predicted with similar confidence whether it's at the edge or the centre of the image. In practice this is only true in the centre of a tile, since at the edges the network sees blank data and has less context to make the prediction. To avoid these edge effects, images are tiled in an overlapping fashion with the overap roughly equal to one \"receptive field\" of the network. Empirically, 512 px gives a good result in most cases.\n",
    "\n",
    "Our pipeline provides some simple utility functions to generate arbitrary resolution tiles from a source orthomosaic. Since the model is trained at 10 cm/px, we resample imagery to that resolution (nominally) though we also perform some augmentation at prediction-time.\n",
    "\n",
    "Drone orthomosaics are often much higher quality, at 1-5cm/px so we have to resample. We provide two options:\n",
    "\n",
    " - Resize the image on the fly\n",
    " - Resample the image and store to disk\n",
    " \n",
    "The first option is fast and works if you want to process an image once. If you think you're likely to experiment with different prediction settings, resampling as a one-time process might make more sense. Rescaling on the fly is also approximate and assumes that linear scaling is appropriate. You might find that you get different results if you compare both methods, but it shouldn't affect things much.\n",
    " \n",
    "In order to plug in to machine learning pipelines, we provide a `SingleImageDataset` that takes a single image as an input and returns tile \"samples\". You can then iterate over this dataset sequentially to load all the tiles (e.g. you can directly pass it to a dataloader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, target_gsd=0.1, tile_size=1024, overlap=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003108f",
   "metadata": {},
   "source": [
    "The arguments to the function are mostly self-explanatory:\n",
    "\n",
    "- The input `test_image`, which can be a path to a file or an existing `rasterio.DatasetReader`\n",
    "- We specify our desired Ground Sample Distance (GSD), here 0.6 metres\n",
    "- Samples will be returned at the requested `tile_size` with some `overlap`\n",
    "\n",
    "Overlap is important. Since we're cutting the image into pieces, we have to consider that there may be objects at the edge of the frame that might be missed. To get around this, we can overlap the tiles by a small amount. This problem also manifests as worse predictions near the edges of the image, since the model doesn't have the full context that it would at the centre. You need to account for this when you merge tiled predictions!\n",
    "\n",
    "It's important that the tile size is large enough to capture enough context about the image, and ideally large enough that the model can take full advantage of its receptive field (around 512 px for ResNet50). This implies that a good rule of thumb for tile size is no smaller than a single receptive field. The overlap is a bit more complicated:\n",
    "\n",
    "- It should be larger than the largest single \"thing\" that you want to detect, for example if a tree can be 50 metres wide, you'd want to make sure that your overlap is double that. Imagine the worst case where a tree is say 100 px wide and 10 px are off the edge of the image. We\n",
    "- Ideally it should be a full receptive field, but practically half is OK (so 256 px is common)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65510460",
   "metadata": {},
   "source": [
    "Let's have a look at what these settings produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualise(midpoints=True, edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b2402",
   "metadata": {},
   "source": [
    "The pipeline generates tiles that are centre-weighted. This should not significantly affect your results, but it does mean that the image is processed symmetrically.\n",
    "\n",
    "Due to the way the image is indexed, the first tile is in the upper left (i.e. not at 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd37e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualise([0], edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1a68f",
   "metadata": {},
   "source": [
    "Tilling proceeds to the right and then down (here we skip tile i=2 for clarity). The tiler will automatically expand the overlap if it's possible to do so. For example for any requested overlap that is less than `(tile_size - (image_width/n_tiles))` we can expand the overlap without adding more computation.\n",
    "\n",
    "This becomes relevant later on because you can discard a larger edge region from each (interior) tile which will give potentially better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualise([0,1,3], edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce2f75",
   "metadata": {},
   "source": [
    "To see the effect of symmetric sampling more, we can have a look at increasing the overlap to a very large value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleImageGeoDataset(test_image, target_gsd=0.1, tile_size=1024, overlap=700).visualise(midpoints=True, edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab102cb",
   "metadata": {},
   "source": [
    "If we set zero overlap, then we simply grid the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleImageGeoDataset(test_image, target_gsd=0.1, tile_size=1024, overlap=0).visualise(midpoints=True, edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74920b",
   "metadata": {},
   "source": [
    "What happens if you set a tile size that's very slightly smaller than the width or height of the image? The tiler will first determine how many tiles are needed given the provided overlap, for a 2048x2048 image with 2047x2047 tiles, we need at least 2 tiles in each direction. Again, the tiler will maximise the overlap for the minimum number of tiles required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, target_gsd=0.1, tile_size=2047, overlap=0)\n",
    "ds.visualise(midpoints=True, edges=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c98db",
   "metadata": {},
   "source": [
    "This assumed that we didn't want to do any resampling (the base image has a GSD of 0.1). What happens if we want to sample at 0.2m/px?\n",
    "\n",
    "Note here we visualise the entire image and all tiles (i.e. one) - the tile locations here are pre-scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef45a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, target_gsd=0.2, tile_size=1024, overlap=256)\n",
    "ds.visualise(midpoints=True, edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea924e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If instead we visualise a tile, we see it's the correct size of 1024x1024\n",
    "    \n",
    "ds.visualise_tile(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25986712",
   "metadata": {},
   "source": [
    "Resampling happens in the following order:\n",
    "\n",
    "1. Image windows are generated based on the bounds of the image\n",
    "2. The image windows are transformed from geographic extent to pixel values\n",
    "3. This region is read from the image\n",
    "4. We compute the scale factor from the source to the target GSD\n",
    "5. The image is blurred by this scale factor and then resized\n",
    "\n",
    "The tiler first establishes whether the output image size can be achieved with zero overlap, for example here we've got a 2048 px image at 0.1 m/px and we request a 1024 px tile at 0.2 m/px. The extent is the same, so no overlap is required.\n",
    "\n",
    "As a general rule, the tiler _should_ produce a set of tiles that satisfy maximum overlap, subject to the provided minimum, with the minimum required number of tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a696ee",
   "metadata": {},
   "source": [
    "Be careful selecting very large overlaps. This will produce a very small stride, for example below only 20 px which will result in ~100 slices in each axis (2048 / (1020-1000)^2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b95c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, target_gsd=0.1, tile_size=1020, overlap=1000)\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf9676c",
   "metadata": {},
   "source": [
    "Ok great. Let's look at some tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3560dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualise_tile(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e48c3",
   "metadata": {},
   "source": [
    "The tiler will automatically pad the image with nodata values. Following suggestions from the original UNet paper (see Figure 2), and () when we predict on this image, we will want to ignore some of the data at the edge because the predictive power is worse there for reasons we discussed earlier (lack of data at the edges). This is the highlighted (green) area in the plot below. Note that with more recent Transformer-based models, this logic may not be quite as simple - these models have a more complex receptive field and in theory suffer less from edge effects compared to CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualise_tile(0, show_valid=True, valid_pad=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59380a08",
   "metadata": {},
   "source": [
    "If you don't want to return fixed size tiles, you can use `pad=False` in the dataset, which will return rectangular images near the edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5305f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, pad_if_needed=False)\n",
    "ds.visualise_tile(0, show_valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b4234",
   "metadata": {},
   "source": [
    "How do we handle edge cases?\n",
    "\n",
    "First, what happens if you suggest a tile equal to the image dimensions? No problem, we get one tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bec239",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, target_gsd=0.1, tile_size=2048, overlap=256)\n",
    "ds.visualise_tile(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ff9b2",
   "metadata": {},
   "source": [
    "Larger? Also no problem, your image will be embedded in the tile size if you like, but you should specify `clip_tiles=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865211db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, target_gsd=0.1, tile_size=4096, overlap=256)\n",
    "ds.visualise_tile(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6c980",
   "metadata": {},
   "source": [
    "This is also handled if you request a different GSD to the source image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa04eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SingleImageGeoDataset(test_image, target_gsd=0.15, tile_size=1024, overlap=512)\n",
    "ds.visualise(midpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4338429",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualise_tile(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
